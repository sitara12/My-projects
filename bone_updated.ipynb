{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNRlNvJ9odMxvsSUeh6y9da",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sitara12/My-projects/blob/main/bone_updated.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "BcY72WyFbxXH",
        "outputId": "b3df05e0-4c7a-4cfe-fa6d-ce933e7146aa"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "BadZipFile",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-da7dda791fba>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Extract the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestination_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextracted_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1267\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1269\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_RealGetContents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1270\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m                 \u001b[0;31m# set the modified flag so central directory gets written\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36m_RealGetContents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1334\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mendrec\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBadZipFile\u001b[0m: File is not a zip file"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from PIL import Image\n",
        "\n",
        "# Specify the path to your dataset ZIP file\n",
        "destination_path = '/content/BoneFractureDataset.zip'\n",
        "\n",
        "# Specify the directory where you want to extract the dataset\n",
        "extracted_dir = '/content/BoneFractureDataset'\n",
        "\n",
        "# Extract the dataset\n",
        "with zipfile.ZipFile(destination_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extracted_dir)\n",
        "\n",
        "# Define functions for image preprocessing and label extraction\n",
        "def preprocess_image(image_path):\n",
        "    img = Image.open(image_path)\n",
        "    img = img.resize((image_height, image_width))\n",
        "    img = np.array(img) / 255.0\n",
        "    return img\n",
        "\n",
        "def extract_label_from_filename(filename):\n",
        "    label = 1 if \"fractured\" in filename else 0\n",
        "    return label\n",
        "\n",
        "# Define image dimensions and number of channels\n",
        "image_height, image_width, num_channels = 128, 128, 3\n",
        "\n",
        "# Define the paths to your dataset folders\n",
        "train_data_path = os.path.join(extracted_dir, 'train')\n",
        "val_data_path = os.path.join(extracted_dir, 'val')\n",
        "\n",
        "# Function to load data\n",
        "def load_data(data_dir):\n",
        "    image_data = []\n",
        "    labels = []\n",
        "    for label in os.listdir(data_dir):\n",
        "        label_dir = os.path.join(data_dir, label)\n",
        "        if os.path.isdir(label_dir):\n",
        "            for image_file in os.listdir(label_dir):\n",
        "                img = preprocess_image(os.path.join(label_dir, image_file))\n",
        "                image_data.append(img)\n",
        "                labels.append(extract_label_from_filename(image_file))\n",
        "    return np.array(image_data), np.array(labels)\n",
        "\n",
        "# Load training and validation data\n",
        "X_train_images, y_train_images = load_data(os.path.join(train_data_path, 'fractured'))\n",
        "X_train_images_non_fractured, y_train_images_non_fractured = load_data(os.path.join(train_data_path, 'non-fractured'))\n",
        "X_val_images, y_val_images = load_data(os.path.join(val_data_path, 'fractured'))\n",
        "X_val_images_non_fractured, y_val_images_non_fractured = load_data(os.path.join(val_data_path, 'non-fractured'))\n",
        "\n",
        "# Combine fractured and non-fractured data\n",
        "X_train_images = np.concatenate([X_train_images, X_train_images_non_fractured])\n",
        "y_train_images = np.concatenate([y_train_images, y_train_images_non_fractured])\n",
        "X_val_images = np.concatenate([X_val_images, X_val_images_non_fractured])\n",
        "y_val_images = np.concatenate([y_val_images, y_val_images_non_fractured])\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train_images, X_test_images, y_train_images, y_test_images = train_test_split(X_train_images, y_train_images, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train_images.reshape(-1, image_height * image_width * num_channels))\n",
        "X_test = scaler.transform(X_test_images.reshape(-1, image_height * image_width * num_channels))\n",
        "\n",
        "# Train the SVM model\n",
        "svm_model = SVC()\n",
        "svm_model.fit(X_train, y_train_images)\n",
        "\n",
        "# Evaluate the SVM model on the test set\n",
        "y_pred_svm = svm_model.predict(X_test)\n",
        "svm_accuracy = accuracy_score(y_test_images, y_pred_svm)\n",
        "print('SVM Accuracy:', svm_accuracy)\n",
        "\n",
        "# Define the CNN model\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(image_height, image_width, num_channels)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')  # Assuming binary classification (fracture or not)\n",
        "])\n",
        "\n",
        "# Compile the CNN model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the CNN model\n",
        "model.fit(X_train_images, y_train_images, epochs=10, validation_data=(X_val_images, y_val_images))\n",
        "\n",
        "# Evaluate the CNN model\n",
        "test_loss, test_acc = model.evaluate(X_test_images, y_test_images)\n",
        "print(f'CNN Test accuracy: {test_acc}')\n"
      ]
    }
  ]
}